{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b9bc9c",
   "metadata": {},
   "source": [
    "# Common code for Climatologoy, Threshold, Mean STT ,SST Anomaly, SST Trend and MHW days correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common code for Climatologoy, Threshold, Mean STT ,SST Anomaly, SST Trend and MHW days correlation analysis\n",
    "#Run this code first before running other analysis codes\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "import marineHeatWaves as mhw  \n",
    "\n",
    "# convert np.NAN to np.nan to avoid dependency issues\n",
    "import numpy as _np\n",
    "if not hasattr(_np, \"NaN\"):\n",
    "    _np.NaN = _np.nan\n",
    "\n",
    "# File path\n",
    "FILES_GLOB = \"/home/Desktop/Noah_data_1982-2024_SST_daily_mean/sst.day.mean.*.nc\"\n",
    "VAR = \"sst\"\n",
    "CLIM_YEARS: Tuple[int,int] = (1982, 2024)   \n",
    "REGIONS: Dict[str, Dict[str, float]] = {   # modify the lat-lon bounds as per your region\n",
    "    \"Arabian Sea\":    {\"lon_min\": 40.0, \"lon_max\": 78.0,  \"lat_min\": 0.0, \"lat_max\": 30.0},\n",
    "    \"Bay Of Bengal\":   {\"lon_min\": 78.0, \"lon_max\": 110.0, \"lat_min\": 0.0, \"lat_max\": 30.0},\n",
    "    \"North Indian Ocean\": {\"lon_min\": 40.0, \"lon_max\": 110.0, \"lat_min\": 0.0, \"lat_max\": 30.0},\n",
    "}\n",
    "\n",
    "SEASONS = {\"DJF\": [12, 1, 2],\"MAM\": [3, 4, 5],\"JJA\": [6, 7, 8],\"SON\": [9, 10, 11],}\n",
    "season_order = [\"DJF\", \"MAM\", \"JJA\", \"SON\"] \n",
    "OUTDIR = Path(\"outputs\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# leap-aware reference year \n",
    "_ref = pd.date_range(\"2000-01-01\", \"2000-12-31\", freq=\"D\") \n",
    "_doy_to_month = pd.Series(_ref.month.values, index=np.arange(1, 367))\n",
    "_month_to_doy0 = {m: (_doy_to_month[_doy_to_month == m].index.values - 1) for m in range(1, 13)}\n",
    "\n",
    "\n",
    "def open_mfdataset(paths_glob: str, chunks={\"time\": 120}, engine: str = \"netcdf4\") -> xr.Dataset:\n",
    "    paths = sorted(glob(paths_glob))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No files match: {paths_glob}\")\n",
    "    print(f\"[open] {len(paths)} files\")\n",
    "    return xr.open_mfdataset(paths, combine=\"by_coords\", parallel=True, chunks=chunks, engine=engine)\n",
    "\n",
    "def subset_box(ds: xr.Dataset, box: Dict[str, float]) -> xr.Dataset:\n",
    "    latn = \"lat\" if \"lat\" in ds.coords else \"latitude\"\n",
    "    lonn = \"lon\" if \"lon\" in ds.coords else \"longitude\"\n",
    "    return ds.sel({latn: slice(box[\"lat_min\"], box[\"lat_max\"]),lonn: slice(box[\"lon_min\"], box[\"lon_max\"])})\n",
    "\n",
    "def area_weighted_boxmean(da: xr.DataArray) -> xr.DataArray:\n",
    "    latn = \"lat\" if \"lat\" in da.coords else \"latitude\"\n",
    "    w = np.cos(np.deg2rad(da[latn]))\n",
    "    return da.weighted(w).mean(dim=[latn, \"lon\" if \"lon\" in da.coords else \"longitude\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f9a10",
   "metadata": {},
   "source": [
    "# Following script calcultes and plot the Long-term Climatology, 90th and 80th percentile Threshold of Arabian Sea, Bay Of Bengal, North Indian Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-term Climatology, 90th and 80th percentile Threshold of Arabian Sea, Bay Of Bengal, North Indian Ocean\n",
    "\n",
    "def mhw_seas_thresh_doy(da_box: xr.DataArray, clim_years: Tuple[int,int]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    t_index = da_box[\"time\"].to_index()\n",
    "\n",
    "    # safety-clip baseline to data span\n",
    "    y0, y1 = max(clim_years[0], t_index.year.min()), min(clim_years[1], t_index.year.max())\n",
    "\n",
    "    ords = np.array([d.toordinal() for d in t_index], dtype=int)\n",
    "    temp = da_box.values.astype(float)\n",
    "\n",
    "    # clim['seas'] and clim['thresh'] for the 90th percentile \n",
    "    res_90th, clim_90th = mhw.detect(ords, temp, climatologyPeriod=[int(y0), int(y1)], pctile=90, minDuration=5, joinAcrossGaps=True)\n",
    "    seas_full   = np.asarray(clim_90th[\"seas\"])\n",
    "    thresh_90th_full = np.asarray(clim_90th[\"thresh\"])\n",
    "\n",
    "    # clim['seas'] and clim['thresh'] for the 80th percentile \n",
    "    res_80th, clim_80th = mhw.detect(ords, temp, climatologyPeriod=[int(y0), int(y1)], pctile=80, minDuration=5, joinAcrossGaps=True)\n",
    "    thresh_80th_full = np.asarray(clim_80th[\"thresh\"])\n",
    "\n",
    "    # Group by day-of-year to get 366-length curves (leap-aware).\n",
    "    doy = t_index.dayofyear.values\n",
    "    seas_366   = np.full(366, np.nan, float)\n",
    "    thresh_90th_366 = np.full(366, np.nan, float)\n",
    "    thresh_80th_366 = np.full(366, np.nan, float)\n",
    "    for d in range(1, 367): \n",
    "        m = (doy == d)\n",
    "        if m.any():\n",
    "            seas_366[d-1]   = np.nanmean(seas_full[m])\n",
    "            thresh_90th_366[d-1] = np.nanmean(thresh_90th_full[m])\n",
    "            thresh_80th_366[d-1] = np.nanmean(thresh_80th_full[m])\n",
    "    return seas_366, thresh_90th_366, thresh_80th_366\n",
    "\n",
    "# Load dataset\n",
    "ds_annual= open_mfdataset(FILES_GLOB)\n",
    "# Compute curves per region and store\n",
    "curves_annual = {}  \n",
    "for name, box in REGIONS.items():\n",
    "    da = subset_box(ds_annual[[VAR]], box)[VAR]\n",
    "    da_box = area_weighted_boxmean(da)\n",
    "    seas_doy, thresh_90th_doy, thresh_80th_doy = mhw_seas_thresh_doy(da_box, CLIM_YEARS)\n",
    "    curves_annual[name] = {\"seas\": seas_doy, \"90th thresh\": thresh_90th_doy, \"80th thresh\": thresh_80th_doy}\n",
    "\n",
    "# Plotting three stacked panels with shared X-axis\n",
    "x_dates = pd.date_range(\"2000-01-01\", \"2000-12-31\", freq=\"D\")  \n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(11, 8), sharex=True, constrained_layout=True)\n",
    "\n",
    "# use common y-limits for comparability\n",
    "all_vals = np.concatenate([np.r_[v[\"seas\"], v[\"90th thresh\"], v[\"80th thresh\"]] for v in curves_annual.values()])\n",
    "ymin = float(np.nanmin(all_vals)) - 0.2\n",
    "ymax = float(np.nanmax(all_vals)) + 0.2 \n",
    "\n",
    "for ax, (name, ct) in zip(axes, curves_annual.items()):\n",
    "    ax.plot(x_dates, ct[\"seas\"],   label=\"Climatology (Annual)\", color=\"C0\", lw=1.6)\n",
    "    ax.plot(x_dates, ct[\"90th thresh\"], label=\"90th perc Threshold\", ls=\"--\", color= \"#ff7f0e\", lw=1.6)\n",
    "    ax.plot(x_dates, ct[\"80th thresh\"], label=\"80th perc Threshold\", ls=\"--\", color= \"#24fa11\", lw=1.6)\n",
    "    ax.set_ylabel(\"Temp (°C)\")\n",
    "    ax.set_title(f\"{name}: Long- Term Climatology, 90th and 80th perc Threshold ({CLIM_YEARS[0]}–{CLIM_YEARS[1]})\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "year = 2000  \n",
    "tick_dates = []\n",
    "for m in range(1, 13):\n",
    "    tick_dates.append(pd.Timestamp(year, m, 1))\n",
    "    tick_dates.append(pd.Timestamp(year, m, 15))\n",
    "tick_dates.append(pd.Timestamp(year, 12, 31))  \n",
    "\n",
    "axes[-1].set_xticks(tick_dates)\n",
    "axes[-1].xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "axes[-1].set_xlim(x_dates[0], x_dates[-1])\n",
    "axes[-1].set_xlabel(\"Day of Year\")\n",
    "fig.autofmt_xdate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff2e2d",
   "metadata": {},
   "source": [
    "# The Following Script Calcultes and plot the Monthly Climatology, 90th & 80th percentile thresholds for Arabian Sea, Bay Of Bengal, North Indian Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Climatology, 90th & 80th percentile thresholds for Arabian Sea, Bay Of Bengal, North Indian Ocean\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import marineHeatWaves as mhw  \n",
    "\n",
    "\n",
    "FILES_GLOB = \"/home/Desktop/Noah_data_1982-2024_SST_daily_mean/sst.day.mean.*.nc\"\n",
    "VAR = \"sst\"\n",
    "CLIM_YEARS: Tuple[int, int] = (1982, 2024)\n",
    "REGIONS: Dict[str, Dict[str, float]] = {\n",
    "    \"Arabian Sea\":      {\"lon_min\": 20.0, \"lon_max\": 78.0,  \"lat_min\": 0.0, \"lat_max\": 25.0},\n",
    "    \"Bay Of Bengal\":    {\"lon_min\": 78.0, \"lon_max\": 100.0, \"lat_min\": 0.0, \"lat_max\": 25.0},\n",
    "    \"North Indian Ocean\": {\"lon_min\": 20.0, \"lon_max\": 100.0, \"lat_min\": 0.0, \"lat_max\": 25.0},\n",
    "}\n",
    "OUTDIR = Path(\"outputs\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# leap-aware reference year \n",
    "_ref = pd.date_range(\"2000-01-01\", \"2000-12-31\", freq=\"D\") \n",
    "_doy_to_month = pd.Series(_ref.month.values, index=np.arange(1, 367))\n",
    "\n",
    "_month_to_doy0 = {m: (_doy_to_month[_doy_to_month == m].index.values - 1) for m in range(1, 13)}\n",
    "\n",
    "\n",
    "def open_mfdataset(paths_glob: str, chunks={\"time\": 120}, engine: str = \"netcdf4\") -> xr.Dataset:\n",
    "    paths = sorted(glob(paths_glob))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No files match: {paths_glob}\")\n",
    "    return xr.open_mfdataset(paths, combine=\"by_coords\", parallel=True, chunks=chunks, engine=engine)\n",
    "\n",
    "def subset_box(ds: xr.Dataset, box: Dict[str, float]) -> xr.Dataset:\n",
    "    latn = \"lat\" if \"lat\" in ds.coords else \"latitude\"\n",
    "    lonn = \"lon\" if \"lon\" in ds.coords else \"longitude\"\n",
    "    return ds.sel({latn: slice(box[\"lat_min\"], box[\"lat_max\"]),\n",
    "                   lonn: slice(box[\"lon_min\"], box[\"lon_max\"])})\n",
    "\n",
    "def area_weighted_boxmean(da: xr.DataArray) -> xr.DataArray:\n",
    "    latn = \"lat\" if \"lat\" in da.coords else \"latitude\"\n",
    "    w = np.cos(np.deg2rad(da[latn]))\n",
    "    return da.weighted(w).mean(dim=[latn, \"lon\" if \"lon\" in da.coords else \"longitude\"])\n",
    "\n",
    "# doad dataset\n",
    "ds = open_mfdataset(FILES_GLOB, chunks={\"time\": 120}, engine=\"netcdf4\")\n",
    "assert VAR in ds, f\"{VAR} not found in dataset\"\n",
    "\n",
    "# curve for each region\n",
    "results = {}\n",
    "\n",
    "for name, box in REGIONS.items():\n",
    "    da = subset_box(ds[[VAR]], box)[VAR]\n",
    "    da_box = area_weighted_boxmean(da).rename(f\"sst_boxmean_{name}\")\n",
    "    da_box = da_box.compute()\n",
    "    time_np = pd.to_datetime(da_box.time.values)          \n",
    "    temp_np = np.asarray(da_box.values, dtype=float)     \n",
    "    assert temp_np.shape[0] == time_np.shape[0], \"time/temperature length mismatch\"\n",
    "\n",
    "    y0 = max(CLIM_YEARS[0], int(time_np.year.min()))\n",
    "    y1 = min(CLIM_YEARS[1], int(time_np.year.max()))\n",
    "    ords = np.array([d.toordinal() for d in time_np], dtype=int)\n",
    "\n",
    "    # clim['seas'] and clim['thresh'] for the 90th percentile \n",
    "    res90, clim90 = mhw.detect(ords, temp_np, climatologyPeriod=[y0, y1],pctile=90, minDuration=5, joinAcrossGaps=True)\n",
    "    seas_full     = np.asarray(clim90[\"seas\"],   dtype=float)  # daily, same length as time_np\n",
    "    thresh90_full = np.asarray(clim90[\"thresh\"], dtype=float)\n",
    "    assert seas_full.shape[0] == temp_np.shape[0] == time_np.shape[0]\n",
    "\n",
    "    # -clim['seas'] and clim['thresh'] for the 80th percentile \n",
    "    res80, clim80 = mhw.detect(\n",
    "        ords, temp_np, climatologyPeriod=[y0, y1],\n",
    "        pctile=80, minDuration=5, joinAcrossGaps=True\n",
    "    )\n",
    "    thresh80_full = np.asarray(clim80[\"thresh\"], dtype=float)\n",
    "    assert thresh80_full.shape[0] == temp_np.shape[0]\n",
    "\n",
    "    df = pd.DataFrame({\"seas\": seas_full, \"p90\": thresh90_full, \"p80\": thresh80_full}, index=time_np)\n",
    "    g = df.groupby(df.index.dayofyear).mean(numeric_only=True)\n",
    "    days = np.arange(1, 367)\n",
    "    g = g.reindex(days)\n",
    "\n",
    "    seas_366        = g[\"seas\"].to_numpy()\n",
    "    thresh_90th_366 = g[\"p90\"].to_numpy()\n",
    "    thresh_80th_366 = g[\"p80\"].to_numpy()\n",
    "\n",
    "    months = np.arange(1, 13)\n",
    "    monthly_seas = np.array([np.nanmean(seas_366[_month_to_doy0[m]])        for m in months])\n",
    "    monthly_90   = np.array([np.nanmean(thresh_90th_366[_month_to_doy0[m]]) for m in months])\n",
    "    monthly_80   = np.array([np.nanmean(thresh_80th_366[_month_to_doy0[m]]) for m in months])\n",
    "\n",
    "    results[name] = {\n",
    "        \"monthly_seas\": monthly_seas,\n",
    "        \"monthly_90_thresh\": monthly_90,\n",
    "        \"monthly_80_thresh\": monthly_80,\n",
    "    }\n",
    "\n",
    "# plot the combined axis graphs\n",
    "month_labels = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "x = np.arange(1, 13)\n",
    "region_order = list(REGIONS.keys())\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(11, 8), sharex=True, constrained_layout=True)\n",
    "\n",
    "# Common y-limits for comparability\n",
    "all_vals = []\n",
    "for nm in region_order:\n",
    "    all_vals.extend([\n",
    "        results[nm][\"monthly_seas\"],\n",
    "        results[nm][\"monthly_90_thresh\"],\n",
    "        results[nm][\"monthly_80_thresh\"],\n",
    "    ])\n",
    "all_vals = np.concatenate(all_vals)\n",
    "ymin = float(np.nanmin(all_vals)) - 0.2\n",
    "ymax = float(np.nanmax(all_vals)) + 0.2\n",
    "\n",
    "for ax, nm in zip(axes, region_order):\n",
    "    ms   = results[nm][\"monthly_seas\"]\n",
    "    mt90 = results[nm][\"monthly_90_thresh\"]\n",
    "    mt80 = results[nm][\"monthly_80_thresh\"]\n",
    "\n",
    "    ax.plot(x, ms,   marker=\"o\", label=\"Climatology (Monthly)\", color=\"C0\",lw=1.6)\n",
    "    ax.plot(x, mt90, marker=\"s\", label=\"90th perc Threshold\",   ls=\"--\", color=\"#ff7f0e\", lw=1.6)\n",
    "    ax.plot(x, mt80, marker=\"^\", label=\"80th perc Threshold\",   ls=\":\",  color=\"C2\",lw=1.6)\n",
    "\n",
    "    ax.set_ylabel(\"Temp (°C)\")\n",
    "    ax.set_title(f\"{nm}: Monthly Climatology, 90th & 80th Thresholds ({CLIM_YEARS[0]}–{CLIM_YEARS[1]})\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "axes[-1].set_xticks(x)\n",
    "axes[-1].set_xticklabels(month_labels)\n",
    "axes[-1].set_xlabel(\"Month\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b959a",
   "metadata": {},
   "source": [
    "# The Following Script Calcultes and plot the Seasonal Climatology, 90th and 80th percentile Threshold of Arabian Sea, Bay Of Bengal, North Indian Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0da746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Climatology, 90th and 80th percentile Threshold of Arabian Sea, Bay Of Bengal, North Indian Ocean\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CLIM_YEARS: Tuple[int,int] = (1982, 2024) \n",
    "SEASONS = {\n",
    "    \"DJF\": [12, 1, 2],\n",
    "    \"MAM\": [3, 4, 5],\n",
    "    \"JJA\": [6, 7, 8],\n",
    "    \"SON\": [9, 10, 11],\n",
    "}\n",
    "\n",
    "season_order = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "OUTDIR = Path(\"outputs\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Leap-aware DOY→month mapping (using leap year 2000)\n",
    "ref = pd.date_range(\"2000-01-01\", \"2000-12-31\", freq=\"D\")\n",
    "doy_month = ref.month.values              \n",
    "doy_index = np.arange(1, 367)             \n",
    "# Precompute mask for each season over DOY\n",
    "season_to_doymask0 = {\n",
    "    s: np.isin(doy_month, months)         \n",
    "    for s, months in SEASONS.items()\n",
    "}\n",
    "\n",
    "def open_ds(globpat, chunks={\"time\": 120}, engine=\"netcdf4\"):\n",
    "    return xr.open_mfdataset(sorted(glob(globpat)), combine=\"by_coords\",\n",
    "                             chunks=chunks, engine=engine)\n",
    "\n",
    "def subset_box(ds: xr.Dataset, box: Dict[str, float]) -> xr.Dataset:\n",
    "    latn = \"lat\" if \"lat\" in ds.coords else \"latitude\"\n",
    "    lonn = \"lon\" if \"lon\" in ds.coords else \"longitude\"\n",
    "    return ds.sel({latn: slice(box[\"lat_min\"], box[\"lat_max\"]),\n",
    "                   lonn: slice(box[\"lon_min\"], box[\"lon_max\"])})\n",
    "\n",
    "def area_weighted_boxmean(da: xr.DataArray) -> xr.DataArray:\n",
    "    latn = \"lat\" if \"lat\" in da.coords else \"latitude\"\n",
    "    w = np.cos(np.deg2rad(da[latn]))\n",
    "    return da.weighted(w).mean(dim=[latn, \"lon\" if \"lon\" in da.coords else \"longitude\"])\n",
    "\n",
    "def boxmean_doy_curves_seas(da_box: xr.DataArray, baseline=(1982,2024)):\n",
    "\n",
    "    da_box = da_box.compute()\n",
    "\n",
    "    t = pd.to_datetime(da_box.time.values)        \n",
    "    temp = np.asarray(da_box.values, dtype=float)\n",
    "    assert len(t) == len(temp), \"time/temperature length mismatch\"\n",
    "\n",
    "    # Clip baseline to available data\n",
    "    y0 = max(baseline[0], int(t.year.min()))\n",
    "    y1 = min(baseline[1], int(t.year.max()))\n",
    "\n",
    "    ords = np.array([d.toordinal() for d in t], dtype=int)\n",
    "\n",
    "    # clim['seas'] and clim['thresh'] for the 90th percentile \n",
    "    res90, clim90 = mhw.detect(\n",
    "        ords, temp, climatologyPeriod=[y0, y1],\n",
    "        pctile=90, minDuration=5, joinAcrossGaps=True\n",
    "    )\n",
    "    seas_full     = np.asarray(clim90[\"seas\"],   dtype=float)  # same seas for any pctile\n",
    "    thresh90_full = np.asarray(clim90[\"thresh\"], dtype=float)\n",
    "    assert seas_full.shape[0] == len(t) and thresh90_full.shape[0] == len(t)\n",
    "\n",
    "    # clim['seas'] and clim['thresh'] for the 80th percentile \n",
    "    res80, clim80 = mhw.detect(\n",
    "        ords, temp, climatologyPeriod=[y0, y1],\n",
    "        pctile=80, minDuration=5, joinAcrossGaps=True\n",
    "    )\n",
    "    thresh80_full = np.asarray(clim80[\"thresh\"], dtype=float)\n",
    "    assert thresh80_full.shape[0] == len(t)\n",
    "\n",
    "    # Build DataFrame aligned on SAME index, then DOY groupby\n",
    "    df = pd.DataFrame(\n",
    "        {\"seas\": seas_full, \"p90\": thresh90_full, \"p80\": thresh80_full},\n",
    "        index=t\n",
    "    )\n",
    "    g = df.groupby(df.index.dayofyear).mean(numeric_only=True)   \n",
    "    g = g.reindex(doy_index)                                    \n",
    "\n",
    "    return g[\"seas\"].to_numpy(), g[\"p90\"].to_numpy(), g[\"p80\"].to_numpy()\n",
    "\n",
    "#load dataset\n",
    "ds0 = open_ds(FILES_GLOB, engine=\"netcdf4\")\n",
    "\n",
    "results = {}\n",
    "for name, box in REGIONS.items():\n",
    "    ds_r   = subset_box(ds0[[VAR]], box)\n",
    "    da_box = area_weighted_boxmean(ds_r[VAR]).rename(\"sst_boxmean\")\n",
    "\n",
    "    seas_doy, p90_doy, p80_doy = boxmean_doy_curves_seas(da_box, CLIM_YEARS)\n",
    "\n",
    "    # Seasonal aggregation from DOY\n",
    "    seas_vals   = []\n",
    "    p90_vals    = []\n",
    "    p80_vals    = []\n",
    "    for s in season_order:\n",
    "        mask0 = season_to_doymask0[s]     \n",
    "        seas_vals.append(  np.nanmean(seas_doy[mask0]) )\n",
    "        p90_vals.append(   np.nanmean(p90_doy[mask0]) )\n",
    "        p80_vals.append(   np.nanmean(p80_doy[mask0]) )\n",
    "    results[name] = {\n",
    "        \"seas\": np.array(seas_vals),\n",
    "        \"p90\":  np.array(p90_vals),\n",
    "        \"p80\":  np.array(p80_vals),\n",
    "    }\n",
    "\n",
    "# plot the combined axis graphs\n",
    "x = np.arange(4)  # 4 seasons\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(11, 8), sharex=True, constrained_layout=True)\n",
    "\n",
    "# common y-limits across regions and curves\n",
    "all_vals = np.concatenate([np.r_[v[\"seas\"], v[\"p90\"], v[\"p80\"]] for v in results.values()])\n",
    "ymin = float(np.nanmin(all_vals)) - 0.2\n",
    "ymax = float(np.nanmax(all_vals)) + 0.2\n",
    "\n",
    "for ax, nm in zip(axes, results.keys()):\n",
    "    ms   = results[nm][\"seas\"]\n",
    "    mt90 = results[nm][\"p90\"]\n",
    "    mt80 = results[nm][\"p80\"]\n",
    "\n",
    "    ax.plot(x, ms,   marker=\"o\",  lw=1.6, color=\"C0\",     label=\"Climatology (Seasonal)\")\n",
    "    ax.plot(x, mt90, marker=\"s\",  lw=1.6, ls=\"--\", color=\"#ff7f0e\", label=\"90th percentile threshold\")\n",
    "    ax.plot(x, mt80, marker=\"^\",  lw=1.6, ls=\":\",  color=\"C2\",      label=\"80th percentile threshold\")\n",
    "    ax.set_ylabel(\"Temp (°C)\")\n",
    "    ax.set_title(f\"{nm}: Seasonal Climatology, 90th & 80th thresholds ({CLIM_YEARS[0]}–{CLIM_YEARS[1]})\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "axes[-1].set_xticks(x, season_order)\n",
    "axes[-1].set_xlabel(\"Season\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
